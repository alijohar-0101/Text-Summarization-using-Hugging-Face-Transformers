{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ali\\anaconda3\\lib\\site-packages (from transformers) (1.19.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/3a/261b99d6815f6afdd2d35b6420d524305daa17bf430c420dca0115bd1c6c/tokenizers-0.10.1-cp37-cp37m-win_amd64.whl (2.0MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ali\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in c:\\users\\ali\\anaconda3\\lib\\site-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\ali\\anaconda3\\lib\\site-packages (from transformers) (0.23)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ali\\anaconda3\\lib\\site-packages (from transformers) (4.46.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/cc/66b24e3c8417aed8359ff7187da64aee86d69d7a2a7036818970cdb1c293/regex-2021.3.17-cp37-cp37m-win_amd64.whl (269kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ali\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ali\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ali\\anaconda3\\lib\\site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ali\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ali\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ali\\anaconda3\\lib\\site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: six in c:\\users\\ali\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in c:\\users\\ali\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\ali\\appdata\\roaming\\python\\python37\\site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ali\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\ali\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->transformers) (7.2.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=cf9bbf83d3b17f1f745924aef7e20641ba787c03b4563869831cf7fd376d83df\n",
      "  Stored in directory: C:\\Users\\Ali\\AppData\\Local\\pip\\Cache\\wheels\\29\\3c\\fd\\7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, regex, sacremoses, transformers\n",
      "Successfully installed regex-2021.3.17 sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation, etc in 100+ languages. Its aim is to make cutting-edge NLP easier to use for everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To immediately use a model on a given text, we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5Model.\n",
      "\n",
      "All the layers of TFT5Model were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#huggingface summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "#URL = \"https://towardsdatascience.com/a-bayesian-take-on-model-regularization-9356116b6457\"\n",
    "URL = \"https://towardsdatascience.com/rosy-ai-5897b1e1b5be\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "results = soup.find_all(['h1', 'p'])\n",
    "text = [result.text for result in results]\n",
    "ARTICLE = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sign in AI Art: Rosy AI Yariv Adan 4 days ago·4 min read In this work, we took a small detour from our main journey, in favour of a short colourful moment of reflection. We kept true to our mission, and used “AI” to generate digital art work, though not in the expected sense. Inspiration It was the summer of 2020, we were discussing new AI & Art projects ideas, and the world around us was spiralling. The dissonance was impossible to ignore. Inside our confined walls, we were surrounded by the vast and fast growing world of AI. Billions of dollars worth of datasets and TPU years, as well thousands of human years captured in research papers. All in the name of an implicit or explicit promise for a better future in science, health, agriculture, energy management, transportation, information consumption, human machine interaction, etc. Yet, it all seemed so disconnected from the reality of the world outside. These marvels of science and technology, these machine olympics — were mesmerising in their inhuman ability to capture details and patterns. However, they were as inhuman in their inability to see neither the issues, nor the bigger picture. But it wasn’t just the machines. Also the human side of AI seemed to be stuck in an infinite loop in some isolated artificial universe. Numerous iterations of research papers, each introducing yet another improvement, each pushing to yet another SOTA on some synthetic benchmark. Yet, on a very basic human level, despite all that progress, as a society, we seem to end up at the same place. We wanted to somehow capture this feeling in a piece of AI art. We wanted to have all the technical pyrotechnics: a large dataset and rich use of its features, machine controlled flow, stochasticity, algorithmic and heuristics diversity, and a touch of visual grandiose. But we didn’t want it to be ML in the regular sense. We wanted to use all of these, and especially the information captured in the dataset in a way that is more accessible to the average human (protesting) on the street. It was also important for us to capture that tension between ingenuity in the details, and big picture blindness. Finally, we wanted to wrap it all in a magical infinite loop, that roller-coasts through marvelled and unique technical paths, just to end up in the exact same place. Rosy AI Rosy AI, is a Python program that applies a human-engineered algorithm to solve a mosaic puzzle, overlaid with an AI model that tries to “understand” the emerging image using state-of-the-art object detection technology. The mosaic is composed of 32K tiles of flower images that were originally compiled as a dataset for the purpose of training AI models in classifying flowers. It seemed to adequately represent the rosey image of AI, as reflected by the walls of its confined universe. Starting from a random distribution or an initial image, tiles are replaced either by some best best fit algorithm, or are randomly selected for a potential switch, if the switch represents a Pareto-improvement in favor of the final image. The human viewer is a witness to AI’s attempts at recognizing the shapes emerging in the mosaic, and by his/her very nature, also a competitor in the race to solve the puzzle. Depending on the geography where the work is presented, the final image may be quite familiar to the local audience (or not so much). Those who’ve seen the photograph in the media numerous times, can easily beat the AI in recognizing the objects in the scene. Whether they are also able to process and understand the big picture better than the AI is a central question of Rosy AI. The final art piece is exhibited as digital video on a screen. It’s not a pre-recorded video file, but rather a computer program running live in an infinite loop that renders a live video on the display. Each iteration of the loop is about 10 minutes long, and it captures the formation of the photo mosaic. When it completes the mosaic, it starts all over again. The loop doesn’t simply repeat itself. Each iteration is unique, and the machine gets to decide on its details: the starting state, the target image (from a collections of candidate images in a dedicated folder), as well as the method it will use to construct the final image (best fit, switch, etc). It’s highly recommended that the viewer watches multiple consecutive runs for a complete impression of the work. Teaser We recorded a few examples for you to enjoy. As you can see, they are quite fun to watch, and generate different results. A small note though:the actual art work is available for both 1800p and 4K displays, and is designed for large screens that allow the viewer to explore the full spectrum from the details of the flower tiles, all the way to the overall image. So if you are reading this on your phone, you might want to rewatch the videos on a bigger screen later :) To be honest, even if not modest — we are happy with the results. After staring at that infinite loop for a while, we think we managed to capture that feeling we aimed for… Product Manager @Google 89  Thanks to The Startup.\\xa0 Every Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don't want to miss.\\xa0Take a look.  By signing up, you will create a Medium account if you don’t already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. 89\\xa0 89\\xa0 Your home for data science. A Medium publication sharing concepts, ideas and codes. About Help Legal Get the Medium app\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chunk = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = ARTICLE.replace('.','.<eos>')\n",
    "ARTICLE = ARTICLE.replace('?','?<eos>')\n",
    "ARTICLE = ARTICLE.replace('!','!<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sentences = ARTICLE.split('<eos>')\n",
    "current_chunk = 0 \n",
    "chunks = []\n",
    "for sentence in sentences:\n",
    "    if len(chunks) == current_chunk + 1: \n",
    "        if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
    "            chunks[current_chunk].extend(sentence.split(' '))\n",
    "        else:\n",
    "            current_chunk += 1\n",
    "            chunks.append(sentence.split(' '))\n",
    "    else:\n",
    "        print(current_chunk)\n",
    "        chunks.append(sentence.split(' '))\n",
    "\n",
    "for chunk_id in range(len(chunks)):\n",
    "    chunks[chunk_id] = ' '.join(chunks[chunk_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = summarizer(chunks, max_length=160, min_length=70, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_text': 'we wanted to capture this feeling in a piece of AI art . despite all that progress, as a society, we seem to end up at the same place . it was important for us to capture that tension between ingenuity in the details, and big picture blindness . but we didn’t want it to be ML in the regular sense .'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join([res['summary_text'] for res in summ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the output to text file\n",
    "with open('Summary.txt', 'w') as f:    \n",
    "    f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
